{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3842a909",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "\n",
    "def extract_text_from_pdf(file_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Safely extracts text from a PDF. Skips pages that cannot be processed.\n",
    "    \"\"\"\n",
    "    text = \"\"\n",
    "    with pdfplumber.open(file_path) as pdf:\n",
    "        for i, page in enumerate(pdf.pages):\n",
    "            try:\n",
    "                page_text = page.extract_text()\n",
    "                if page_text:\n",
    "                    text += page_text + \"\\n\"\n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ Skipping page {i+1} due to error: {e}\")\n",
    "                continue\n",
    "    return text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08a1b2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"mistral-medium\",\n",
    "    openai_api_key=os.getenv(\"MISTRAL_API_KEY\"),\n",
    "    openai_api_base=\"https://api.mistral.ai/v1\",\n",
    "    temperature=0.2\n",
    ")\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"jd_text\"],\n",
    "    template=\"\"\"\n",
    "You are an HR assistant. Read the job description and **infer** the following:\n",
    "\n",
    "1. Bullet list of REQUIRED skills  \n",
    "2. Bullet list of PREFERRED (nice-to-have) skills  \n",
    "\n",
    "Even if the skills aren't explicitly written, guess based on the responsibilities and context.\n",
    "\n",
    "Job Description:\n",
    "---\n",
    "{jd_text}\n",
    "---\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "def extract_skills_from_jd(jd_text: str) -> str:\n",
    "    \"\"\"\n",
    "    Extracts skills from a JD using Mistral API via LangChain.\n",
    "    Returns a clean bullet-format string.\n",
    "    \"\"\"\n",
    "    prompt = prompt_template.format(jd_text=jd_text)\n",
    "    response = llm.invoke([\n",
    "        SystemMessage(content=\"You are an HR assistant skilled in parsing job descriptions.\"),\n",
    "        HumanMessage(content=prompt)\n",
    "    ])\n",
    "    return response.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e119f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Extracted Skills from JD:\n",
      "\n",
      "### Required Skills:\n",
      "- Proficiency in Python programming\n",
      "- Understanding of machine learning concepts and model training\n",
      "- Experience with data analysis and data pipelines\n",
      "- Knowledge of cloud infrastructure and services\n",
      "- Ability to write production-quality code\n",
      "- Familiarity with machine learning frameworks (e.g., TensorFlow, PyTorch)\n",
      "- Basic understanding of software development principles\n",
      "- Strong problem-solving skills\n",
      "- Good communication and teamwork abilities\n",
      "\n",
      "### Preferred (Nice-to-Have) Skills:\n",
      "- Experience with Git for version control\n",
      "- Knowledge of Docker for containerization\n",
      "- Familiarity with SQL databases\n",
      "- Experience with automated deployment workflows\n",
      "- Understanding of scalable ML pipeline development\n",
      "- Previous experience collaborating with research scientists and backend developers\n",
      "- Knowledge of modern machine learning frameworks and tools\n",
      "- Experience in a similar internship or project-based role\n"
     ]
    }
   ],
   "source": [
    "jd_text = extract_text_from_pdf(\"sample_data/jd.pdf\")\n",
    "\n",
    "# Step 2: Extract required/preferred skills using Mistral\n",
    "skills = extract_skills_from_jd(jd_text)\n",
    "\n",
    "# Step 3: Print the result\n",
    "print(\"ðŸ” Extracted Skills from JD:\\n\")\n",
    "print(skills)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fcea6b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Varun\n",
      "[nltk_data]     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Lowercase, remove special chars, and normalize whitespace.\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z0-9\\s]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def match_resume_to_jd(resume_text: str, jd_skills_text: str) -> float:\n",
    "    \"\"\"\n",
    "    Returns cosine similarity between resume and JD skill descriptions.\n",
    "    \"\"\"\n",
    "    resume_clean = clean_text(resume_text)\n",
    "    jd_clean = clean_text(jd_skills_text)\n",
    "\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vectors = vectorizer.fit_transform([jd_clean, resume_clean])\n",
    "    similarity = cosine_similarity(vectors[0], vectors[1])\n",
    "    return round(float(similarity[0][0]), 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd7bd49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_text = extract_text_from_pdf(\"resumes/resume1.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb118042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§  Resume Match Score: 0.25\n"
     ]
    }
   ],
   "source": [
    "score = match_resume_to_jd(resume_text, skills)\n",
    "print(f\"ðŸ§  Resume Match Score: {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ae560bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agents/screening_agent.py\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.agents import AgentType, initialize_agent\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"mistral-medium\",\n",
    "    openai_api_key=os.getenv(\"MISTRAL_API_KEY\"),\n",
    "    openai_api_base=\"https://api.mistral.ai/v1\",\n",
    "    temperature=0.3\n",
    ")\n",
    "\n",
    "# â¬ Prompt Template\n",
    "feedback_prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are an expert HR recruiter.\n",
    "\n",
    "Given the following job description and a candidate's resume, provide a concise and professional feedback.\n",
    "\n",
    "Mention:\n",
    "- Key strengths of the candidate relevant to the JD\n",
    "- Any major skill gaps or missing experience\n",
    "- How well the resume matches the JD overall\n",
    "\n",
    "Job Description:\n",
    "{jd_text}\n",
    "\n",
    "Resume:\n",
    "{resume_text}\n",
    "\n",
    "Your feedback (1-2 sentences):\n",
    "\"\"\")\n",
    "\n",
    "# ðŸ” LLM Chain\n",
    "feedback_chain = LLMChain(llm=llm, prompt=feedback_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b9ab1545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¬ Feedback:\n",
      " **Feedback:**\n",
      "\n",
      "Amit Sharma demonstrates strong alignment with the JD, showcasing relevant skills in Python, ML (scikit-learn), SQL, and AWS, along with hands-on experience in model training and deployment. However, deeper expertise in production-grade ML pipelines and advanced cloud infrastructure could strengthen his fit; overall, his resume matches ~80% of the requirements, making him a promising candidate with minor gaps to address.\n",
      "\n",
      "*(Note: Adjust percentages or specifics based on your evaluation scale.)*\n"
     ]
    }
   ],
   "source": [
    "from agents.screening_agent import feedback_chain\n",
    "\n",
    "jd_text = extract_text_from_pdf(\"sample_data/jd.pdf\")\n",
    "resume_text = extract_text_from_pdf(\"sample_data/resumes/resume1.pdf\")\n",
    "\n",
    "feedback = feedback_chain.invoke({\n",
    "    \"jd_text\": jd_text,\n",
    "    \"resume_text\": resume_text[:2500]  \n",
    "})[\"text\"]\n",
    "\n",
    "print(\"ðŸ’¬ Feedback:\\n\", feedback.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e29946ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('amit_sharma',\n",
       "  0.0,\n",
       "  'Feedback for Sample text extracted from amit_sharma.pdf (truncated)'),\n",
       " ('john_doe',\n",
       "  0.0,\n",
       "  'Feedback for Sample text extracted from john_doe.pdf (truncated)'),\n",
       " ('neha_kumar',\n",
       "  0.0,\n",
       "  'Feedback for Sample text extracted from neha_kumar.pdf (truncated)')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import heapq\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "# Simulated outputs (Youâ€™ll replace with actual implementations)\n",
    "def get_resume_text(file_path: str) -> str:\n",
    "    return f\"Sample text extracted from {os.path.basename(file_path)}\"\n",
    "\n",
    "def get_score(jd_skills: str, resume_text: str) -> float:\n",
    "    return round(len(set(jd_skills.lower().split()) & set(resume_text.lower().split())) / 10, 2)\n",
    "\n",
    "def get_feedback(jd_text: str, resume_text: str) -> str:\n",
    "    return f\"Feedback for {os.path.basename(resume_text[:50])} (truncated)\"\n",
    "\n",
    "# Priority queue logic: stores (-score, name, feedback) for max-heap behavior\n",
    "def build_leaderboard(jd_text: str, jd_skills: str, resume_files: List[str]) -> List[Tuple[str, float, str]]:\n",
    "    pq = []\n",
    "    for file_path in resume_files:\n",
    "        name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "        resume_text = get_resume_text(file_path)\n",
    "        score = get_score(jd_skills, resume_text)\n",
    "        feedback = get_feedback(jd_text, resume_text)\n",
    "        heapq.heappush(pq, (-score, name, feedback))\n",
    "\n",
    "    leaderboard = []\n",
    "    while pq:\n",
    "        score_neg, name, feedback = heapq.heappop(pq)\n",
    "        leaderboard.append((name, -score_neg, feedback))\n",
    "\n",
    "    return leaderboard\n",
    "\n",
    "# Test with dummy files (replace with actual resume file paths)\n",
    "sample_jd_text = \"We are looking for Python, ML, SQL, communication\"\n",
    "sample_jd_skills = \"Python ML SQL communication\"\n",
    "sample_resumes = [\"resumes/amit_sharma.pdf\", \"resumes/neha_kumar.pdf\", \"resumes/john_doe.pdf\"]\n",
    "\n",
    "build_leaderboard(sample_jd_text, sample_jd_skills, sample_resumes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad212c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
